apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: rhtap-konflux-ui-availability-alerting-rules
  labels:
    tenant: rhtap

spec:
  groups:
  - name: konflux-ui-proxy-availability
    interval: 1m
    rules:
    - alert: KonfluxUIProxyDown
      expr: |
        konflux_up{
          namespace="konflux-ui",
          check="replicas-available",
          service="proxy"
        } != 1
      for: 5m
      labels:
        severity: critical
        slo: "true"
      annotations:
        summary: >-
          Konflux UI proxy pod is down in cluster {{ $labels.source_cluster }}
        description: >
          The Konflux UI proxy pod has been down for 5min in cluster {{ $labels.source_cluster }}
        alert_team_handle: <!subteam^S04HY632621>
        team: konflux-ui
        runbook_url: null

  - name: konflux-ui-dex-availability
    interval: 1m
    rules:
    - alert: KonfluxUIDexDown
      expr: |
        konflux_up{
          namespace="konflux-ui",
          check="replicas-available",
          service="dex"
        } != 1
      for: 5m
      labels:
        severity: critical
        slo: "true"
      annotations:
        summary: >-
          Konflux UI dex pod is down in cluster {{ $labels.source_cluster }}
        description: >
          The Konflux UI dex pod has been down for 5min in cluster {{ $labels.source_cluster }}
        alert_team_handle: <!subteam^S04HY632621>
        team: konflux-ui
        runbook_url: null

  - name: konflux-ui-endpoint-availability
    interval: 1m
    rules:
    - alert: KonfluxUIEndpointDown
      expr: |
        sum without (cluster) (kube_endpoint_address{namespace="konflux-ui", endpoint="proxy"}) == 0
      for: 5m
      labels:
        severity: critical
        slo: "true"
      annotations:
        summary: >-
          Konflux UI endpoint is down in cluster {{ $labels.source_cluster }}
        description: >
          There were no Konflux UI proxy pods behind the endopint for 5min in cluster {{ $labels.source_cluster }}
        alert_team_handle: <!subteam^S04HY632621>
        team: konflux-ui
        runbook_url: null

  - name: konflux-ui-http-error-rate
    interval: 1m
    rules:
    - alert: KonfluxUIHttpHighErrorRate
      expr: |
        sum by (job, source_cluster) (nginx_otel_http_request_errors:rate5m)
        >
        sum by (job, source_cluster) (
          (nginx_otel_http_request_errors:rate24h_avg)
          +
          3 * (nginx_otel_http_request_errors:rate24h_stddev)
        )
      for: 5m
      labels:
        severity: warning
        slo: "false"
      annotations:
        summary: >-
          Konflux UI HTTP endpoints are experiencing a high error rate in cluster {{ $labels.source_cluster }}
        description: >
          The Konflux UI HTTP endpoints have been experiencing a high error rate for 5min in cluster {{ $labels.source_cluster }}
        alert_routing_key: konflux-ui
        team: konflux-ui
        runbook_url: null

  - name: konflux-ui-5xx-http-error-rate
    interval: 1m
    rules:
    - alert: KonfluxUIHttpHigh5xxErrorRate
      expr: |
        sum by (job, source_cluster) (nginx_otel_http_request_errors:rate5m{status=~"5.."})
        >
        sum by (job, source_cluster) (
          (nginx_otel_http_request_errors:rate24h_avg{status=~"5.."})
          +
          3 * (nginx_otel_http_request_errors:rate24h_stddev{status=~"5.."})
        )
      for: 5m
      labels:
        severity: warning
        slo: "false"
      annotations:
        summary: >-
          Konflux UI HTTP endpoints are experiencing a high 5xx error rate in cluster {{ $labels.source_cluster }}
        description: >
          The Konflux UI HTTP endpoints have been experiencing a high 5xx error rate for 5min in cluster {{ $labels.source_cluster }}
        alert_routing_key: spre
        team: spre
        runbook_url: null